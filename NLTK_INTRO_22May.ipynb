{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task 1 - nltk download\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task 2 - import brown corpus and accessing data\n",
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dan', 'Morgan', 'told', 'himself', 'he', 'would', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='adventure')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There',\n",
       " 'were',\n",
       " 'thirty-eight',\n",
       " 'patients',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'the',\n",
       " 'morning',\n",
       " 'I']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='mystery')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'was',\n",
       " 'among',\n",
       " 'these',\n",
       " 'that',\n",
       " 'Hinkle',\n",
       " 'identified',\n",
       " 'a',\n",
       " 'photograph',\n",
       " 'of']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='humor')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task 3 - import inaugural corpus and access data\n",
    "#includes every president's inaugural address fromm 1789 to 2009\n",
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'fellow',\n",
       " 'citizens',\n",
       " ':',\n",
       " 'I',\n",
       " 'stand',\n",
       " 'here',\n",
       " 'today',\n",
       " 'humbled',\n",
       " 'by',\n",
       " 'the',\n",
       " 'task',\n",
       " 'before',\n",
       " 'us',\n",
       " ',',\n",
       " 'grateful',\n",
       " 'for',\n",
       " 'the',\n",
       " 'trust',\n",
       " 'you']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words(fileids='2009-Obama.txt')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chief',\n",
       " 'Justice',\n",
       " 'Roberts',\n",
       " ',',\n",
       " 'President',\n",
       " 'Carter',\n",
       " ',',\n",
       " 'President',\n",
       " 'Clinton',\n",
       " ',',\n",
       " 'President',\n",
       " 'Bush',\n",
       " ',',\n",
       " 'President',\n",
       " 'Obama',\n",
       " ',',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " ',',\n",
       " 'and']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words(fileids= '2017-Trump.txt')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow',\n",
       " '-',\n",
       " 'Citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ':',\n",
       " 'In',\n",
       " 'compliance',\n",
       " 'with',\n",
       " 'a',\n",
       " 'custom',\n",
       " 'as',\n",
       " 'old',\n",
       " 'as',\n",
       " 'the',\n",
       " 'Government',\n",
       " 'itself',\n",
       " ',']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words(fileids= '1861-Lincoln.txt')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firefox.txt Cookie Manager: \"Don't allow sites that set removed cookies to set future cookies\" should stay checked\r\n",
      "When in full screen mode\r\n",
      "Pressing Ctrl-N should open a new browser when only download dialog is left open\r\n",
      "add icons to context menu\r\n",
      "So called \"tab bar\" should be made a proper toolbar or given the ability collapse / expand.\r\n",
      "[XUL] Implement Cocoa-style toolbar customization.\r\n",
      "#ifdefs for MOZ_PHOENIX\r\n",
      "customize dialog's toolbar has small icons when small icons is not checked\r\n",
      "nightly builds and tinderboxen for Phoenix\r\n",
      "finish tearing prefs UI to pieces and then make it not suck\r\n",
      "\"mozbrowser\" script doesn't start correct binary\r\n",
      "Need bookmark groups icon\r\n",
      "Dropping at top of palette box horks things\r\n",
      "keyboard shortcut for Increase Text Size is broken\r\n",
      "default phoenix bookmarks\r\n",
      "[cust] need a toolbar spacer and spring spacer for customize\r\n",
      "Can't launch phoenix while Mozilla is running (or vice versa)\r\n",
      "separator not available when all toolbar items are in toolbar layout\r\n",
      "history menu f\n",
      "grail.txt SCENE 1: [wind] [clop clop clop] \n",
      "KING ARTHUR: Whoa there!  [clop clop clop] \n",
      "SOLDIER #1: Halt!  Who goes there?\n",
      "ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\n",
      "SOLDIER #1: Pull the other one!\n",
      "ARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\n",
      "SOLDIER #1: What?  Ridden on a horse?\n",
      "ARTHUR: Yes!\n",
      "SOLDIER #1: You're using coconuts!\n",
      "ARTHUR: What?\n",
      "SOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\n",
      "ARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\n",
      "SOLDIER #1: Where'd you get the coconuts?\n",
      "ARTHUR: We found them.\n",
      "SOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\n",
      "ARTHUR: What do you mean?\n",
      "SOLDIER #1: Well, this is a temperate zone.\n",
      "AR\n",
      "overheard.txt White guy: So, do you have any plans for this evening?\n",
      "Asian girl: Yeah, being angry!\n",
      "White guy: Oh, that sounds good.\n",
      "\n",
      "Guy #1: So this Jack guy is basically the luckiest man in the world.\n",
      "Guy #2: Why, because he's survived like 5 attempts on his life and it's not even noon?\n",
      "Guy #1: No; he could totally nail those two chicks.\n",
      "\n",
      "Dad: Could you tell me where the auditorium is?\n",
      "Security guy: It's on the second floor.\n",
      "Dad: Wait, you mean it's actually in the building?\n",
      "\n",
      "Girl: But, I mean, it's not like I ever plan on giving birth.\n",
      "Guy: Well, if your mother gave birth, it's like your chances are good that you'll give birth too.\n",
      "Girl: ...Uh, dude, mother gave birth.\n",
      "Guy: Absolutely.\n",
      "Guy #1: I don't mind getting old; I love getting old.\n",
      "Guy #2: Yeah, just as long as you don't get pregnant.\n",
      "\n",
      "Hobo: Can you spare any change?\n",
      "Man: Sorry, no.\n",
      "Hobo: Who the hell you saying no to? I wasn't asking you anyway, asshole!\n",
      "\n",
      "Hobo: Excuse me, this is a picture of my daughter Sofiya, she was in a fire recently\n",
      "pirates.txt PIRATES OF THE CARRIBEAN: DEAD MAN'S CHEST, by Ted Elliott & Terry Rossio\n",
      "[view looking straight down at rolling swells, sound of wind and thunder, then a low heartbeat]\n",
      "Scene: PORT ROYAL\n",
      "[teacups on a table in the rain]\n",
      "[sheet music on music stands in the rain]\n",
      "[bouquet of white orchids, Elizabeth sitting in the rain holding the bouquet]\n",
      "[men rowing, men on horseback, to the sound of thunder]\n",
      "[EITC logo on flag blowing in the wind]\n",
      "[many rowboats are entering the harbor]\n",
      "[Elizabeth sitting alone, at a distance]\n",
      "[marines running, kick a door in] \n",
      "[a mule is seen on the left in the barn where the marines enter]\n",
      "[Liz looking over her shoulder]\n",
      "[Elizabeth drops her bouquet]\n",
      "[Will is in manacles, being escorted by red coats]\n",
      "ELIZABETH SWANN: Will...!\n",
      "[Elizabeth runs to Will]\n",
      "ELIZABETH SWANN: Why is this happening? \n",
      "WILL TURNER: I don't know. You look beautiful.\n",
      "ELIZABETH SWANN: I think it's bad luck for the groom to see the bride before the wedding.\n",
      "[marines cross their long axes to bar Go\n",
      "singles.txt 25 SEXY MALE, seeks attrac older single lady, for discreet encounters.\n",
      "35YO Security Guard, seeking lady in uniform for fun times.\n",
      "40 yo SINGLE DAD, sincere friendly DTE seeks r/ship with fem age open S/E\n",
      "44yo tall seeks working single mum or lady below 45 fship rship. Nat Open\n",
      "6.2 35 yr old OUTGOING M seeks fem 28-35 for o/door sports - w/e away\n",
      "A professional business male, late 40s, 6 feet tall, slim build, well groomed, great personality, home owner, interests include the arts travel and all things good, Ringwood area, is seeking a genuine female of similar age or older, in same area or surrounds, for a meaningful long term rship. Looking forward to hearing from you all.\n",
      "ABLE young man seeks, sexy older women. Phone for fun ready to play\n",
      "AFFECTIONATE LADY Sought by generous guy, 40s, mutual fulfillment\n",
      "ARE YOU ALONE or lost in a r/ship too, with no hope in sight? Maybe we could explore new beginnings together? Im 45 Slim/Med build, GSOH, high needs and looking for someone similar. \n",
      "wine.txt Lovely delicate, fragrant Rhone wine. Polished leather and strawberries. Perhaps a bit dilute, but good for drinking now. ***\n",
      "Liquorice, cherry fruit. Simple and coarse at the finish. **\n",
      "Thin and completely uninspiring. *\n",
      "Rough. No Stars\n",
      "Big, fat, textured Chardonnay - nuts and butterscotch. A slightly odd metallic/cardboard finish, but probably ***\n",
      "A blind tasting, other than the fizz, which included five vintages of Cote Rotie Brune et Blonde from Guigal.\n",
      "Surprisingly young feeling and drinking well, but without any great complexity. A good ***\n",
      "Charming, violet-fragranced nose. Classic Guigal Cote Rotie. ****\n",
      "Good grip and a touch of rusticity on the length. VA showing through. On the downhill slope. Just ****\n",
      "Just about holding together - drying out a touch at the finish. Not as good as I thought this would be.  A good ***\n",
      "In your face wine - rather obvious and simple (although some structure did begin to show through). ***\n",
      "Some volatility, and all over the place on the nose and pal\n"
     ]
    }
   ],
   "source": [
    "# task 4 - importing webtext corpus and access data\n",
    "from nltk.corpus import webtext\n",
    "webtext.fileids()\n",
    "\n",
    "for fileid in webtext.fileids():\n",
    "    print(fileid, webtext.raw(fileid)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 102 samples and 137 outcomes>\n"
     ]
    }
   ],
   "source": [
    "#task 5 - distribution of words in a text\n",
    "text1 = 'As long as computers have been around, programmers have been trying to write programs that understand languages like English. The reason is pretty obvious — humans have been writing things down for thousands of years and it would be really helpful if a computer could read and understand all that data. Computers can’t yet truly understand English in the way that humans do — but they can already do a lot! In certain limited areas, what you can do with NLP already seems like magic. You might be able to save a lot of time by applying NLP techniques to your own projects. And even better, the latest advances in NLP are easily accessible through open source Python libraries like spaCy, textacy, and neuralcoref. What you can do with just a few lines of python is amazing.'\n",
    "fd = nltk.FreqDist(text1.split())\n",
    "print(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'a': 4, 'do': 4, 'have': 3, 'been': 3, 'to': 3, 'that': 3, 'understand': 3, 'like': 3, 'of': 3, 'and': 3, ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'and': 3, 'can': 3, 'NLP': 3, 'the': 2, 'you': 2, 'The': 1, 'for': 1, 'all': 1, 'yet': 1, 'way': 1, ...})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task 6 conditional frequency distribution of words in a text\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "cfd = ConditionalFreqDist((len(word),word) for word in text1.split())\n",
    "cfd[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HomeWork below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'fellow', 'citizens', ':', 'I', 'stand', 'here', ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat task5,6 for any inaugural speech ; 4,5,6 word count in conditional ; max word count \n",
    "text2 = inaugural.words(fileids='2009-Obama.txt')\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 938 samples and 2726 outcomes>\n"
     ]
    }
   ],
   "source": [
    "fd2 = nltk.FreqDist(text2)\n",
    "print(fd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 126, 'and': 105, 'our': 58, 'are': 22, 'but': 17, 'not': 16, 'for': 15, 'you': 14, 'has': 14, 'who': 14, ...})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here maximum word count is 126 of 'the' word considering different lengths\n",
    "# but , is used maximum times if character length is considered, program is given below\n",
    "\n",
    "cfd2 = ConditionalFreqDist((len(word),word) for word in text2)\n",
    "cfd2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'of': 82, 'to': 66, 'we': 50, 'is': 36, 'us': 23, 'in': 22, '--': 22, 'on': 15, 'it': 15, 'We': 12, ...})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd2 = ConditionalFreqDist((len(word),word) for word in text2)\n",
    "cfd2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'that': 48, 'this': 20, 'will': 19, 'have': 16, 'with': 11, 'they': 11, 'been': 8, 'must': 8, 'than': 8, 'when': 7, ...})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd2 = ConditionalFreqDist((len(word),word) for word in text2)\n",
    "cfd2[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'those': 10, 'their': 9, 'every': 8, 'these': 7, 'world': 7, 'today': 5, 'words': 4, 'peace': 4, 'women': 4, 'power': 4, ...})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd2 = ConditionalFreqDist((len(word),word) for word in text2)\n",
    "cfd2[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'nation': 12, 'cannot': 6, 'common': 6, 'people': 6, 'spirit': 5, 'before': 4, 'crisis': 4, 'things': 4, 'ideals': 3, 'across': 3, ...})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd2 = ConditionalFreqDist((len(word),word) for word in text2)\n",
    "cfd2[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### program created for maximum used word/character in given document (Obama speech <- in this case) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ Word & its Count used for maximum times iterated for word length upto 10 ___________________\n",
      "\n",
      ",  counted: 130 for char len 1\n",
      "of  counted: 82 for char len 2\n",
      "the  counted: 126 for char len 3\n",
      "that  counted: 48 for char len 4\n",
      "those  counted: 10 for char len 5\n",
      "nation  counted: 12 for char len 6\n",
      "America  counted: 10 for char len 7\n",
      "question  counted: 3 for char len 8\n",
      "Americans  counted: 3 for char len 9\n",
      "generation  counted: 5 for char len 10\n"
     ]
    }
   ],
   "source": [
    "n={}\n",
    "print(\"_______ Word & its Count used for maximum times iterated for word length upto 10 ___________________\\n\")\n",
    "for i in range(1,11):\n",
    "    cfd2 = ConditionalFreqDist((len(word),word) for word in text2)\n",
    "    n.update(cfd2[i])\n",
    "    k = max(n,key=n.get)\n",
    "    print(k,\" counted:\", max(n.values()),\"for char len\",i)\n",
    "    n.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
